{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class MakeEmbeddings:\n",
    "    '''\n",
    "    Experimental stimuli from Allen Brain Observatory are\n",
    "    transformed with a HuggingFace Transformer defined at initialization\n",
    "    and the resulting embeddings are saved to the cache specified in the\n",
    "    HGMS_TRANSF_EMBEDDING_PATH environment variable. \n",
    "    '''\n",
    "    allen_cache_path = os.environ.get('HGMS_ALLEN_CACHE_PATH')\n",
    "\n",
    "    # Experiments where these three types of movies were played\n",
    "    session_A = 501704220  # This is three session A\n",
    "    session_B = 501559087\n",
    "    session_C = 501474098\n",
    "    boc = BrainObservatoryCache(manifest_file=str(\n",
    "        Path(allen_cache_path) / Path('brain_observatory_manifest.json')))\n",
    "    transformer_embedding_cache_path = os.environ.get(\n",
    "        'HGMS_TRANSF_EMBEDDING_PATH')\n",
    "    raw_data_dct = {}\n",
    "    movie_one_dataset = boc.get_ophys_experiment_data(session_A)\n",
    "    raw_data_dct['natural_movie_one'] = movie_one_dataset.get_stimulus_template(\n",
    "        'natural_movie_one')\n",
    "    movie_two_dataset = boc.get_ophys_experiment_data(session_C)\n",
    "    raw_data_dct['natural_movie_two'] = movie_two_dataset.get_stimulus_template(\n",
    "        'natural_movie_two')\n",
    "    movie_three_dataset = boc.get_ophys_experiment_data(session_A)\n",
    "    raw_data_dct['natural_movie_three'] = movie_three_dataset.get_stimulus_template(\n",
    "        'natural_movie_three')\n",
    "\n",
    "    def __init__(self, processor, model):\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def process_stims(self, stims):\n",
    "        def get_pooler_dim(single_stim, processor, model):\n",
    "            inputs = processor(images=single_stim, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            cls = outputs.pooler_output.squeeze().detach().numpy()\n",
    "            return cls.shape[-1]\n",
    "        import time\n",
    "        start = time.time()\n",
    "        n_stims = len(stims)\n",
    "        # n_stims=10\n",
    "        stims_dim = np.repeat(stims[:, np.newaxis, :, :], 3, axis=1)\n",
    "        single_stim = stims_dim[0]\n",
    "        pooler_dim = get_pooler_dim(single_stim, self.processor, self.model)\n",
    "        embeddings = np.empty((n_stims, pooler_dim))\n",
    "        for i in range(n_stims):\n",
    "            # print(i)\n",
    "            inputs = self.processor(images=stims_dim[i], return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            cls = outputs.pooler_output.squeeze().detach().numpy()\n",
    "            embeddings[i, :] = cls\n",
    "        end = time.time()\n",
    "        print('Time taken for embedding one movie: ', end-start)\n",
    "        return embeddings\n",
    "\n",
    "    def save_to_cache(self, embeddings_dct):\n",
    "        # Replace / with _ for valid file name\n",
    "        model_string = self.model.name_or_path.replace('/', '_')\n",
    "        file_name = model_string+'_embeddings.pkl'\n",
    "        # Pickle the dictionary\n",
    "        save_path = Path(\n",
    "            self.transformer_embedding_cache_path) / Path(file_name)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(embeddings_dct, f)\n",
    "\n",
    "    def execute(self):\n",
    "        embeddings_dct = {}\n",
    "        for key in self.raw_data_dct.keys():\n",
    "            print(self.raw_data_dct[key].shape)\n",
    "            embeddings_dct[key] = self.process_stims(self.raw_data_dct[key])\n",
    "        self.save_to_cache(embeddings_dct)\n",
    "        return embeddings_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 304, 608)\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "\n",
    "model='google/vit-base-patch16-224'\n",
    "processor = ViTImageProcessor.from_pretrained(model)\n",
    "model = ViTModel.from_pretrained(model)\n",
    "\n",
    "MakeEmbeddings(processor, model).execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
