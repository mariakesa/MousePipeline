{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "['Lo220426', 'Re220308', 'Na220408', 'Na220509', 'Ve220408', 'Oc220410', 'Oc220505', 'Re220311', 'Bo220321', 'Lo220516', 'Bo220414', 'Og220407', 'Lo220511', 'Lo220430', 'Lo220421', 'Bo220420', 'Oc220511', 'Bo220402', 'Oc220417', 'Og220517', 'Lo220518', 'Lo220515', 'Re220326', 'Bo220322', 'Oc220406', 'Oc220502', 'Oc220416', 'Oc220428', 'Ve220407', 'Og220325', 'Lo220428', 'Re220413', 'Ve220302', 'Oc220513', 'Re220409', 'Og220507', 'Lo220502', 'Oc220509', 'Lo220517', 'Ve220312', 'Re220318', 'Pa220428', 'Re220421', 'Og220514', 'Lo220420', 'Re220306', 'Ve220317', 'Og220328', 'Lo220503', 'Re220404', 'Oc220423', 'Ve220313', 'Oc220421', 'Lo220508', 'Og220518', 'Re220425', 'Ve220228', 'Oc220420', 'Re220401', 'Ve220303', 'Og220523', 'Oc220409', 'Oc220504', 'Oc220415', 'Ve220322', 'Bo220406', 'Re220305', 'Ve220326', 'Ve220406', 'Pa220430', 'Bo220404', 'Bo220419', 'Lo220506', 'Pa220503', 'Ve220309', 'Ve220307', 'Re220422', 'Og220521', 'Re220414', 'Bo220325', 'Pa220504', 'Bo220329', 'Oc220419', 'Bo220412', 'Bo220320', 'Na220407', 'Og220513', 'Na220409', 'Ve220319', 'Ve220405', 'Ve220329', 'Bo220326', 'Oc220429', 'Na220406', 'Lo220507', 'Oc220414', 'Ve220409', 'Lo220509', 'Ve220413', 'Pa220505', 'Og220509', 'Og220321', 'Re220412', 'Na220411', 'Ve220404', 'Re220416', 'Bo220525', 'Bo220415', 'Og220503', 'Ve220301', 'Ve220315', 'Og220326', 'Re220320', 'Bo220312', 'Lo220514', 'Og220408', 'Og220512', 'Ve220304', 'Lo220427', 'Oc220411', 'Oc220507', 'Oc220426', 'Oc220425', 'Lo220423', 'Ve220412', 'Lo220429', 'Og220505', 'Oc220427', 'Og220324', 'Pa220506', 'Lo220425', 'Bo220416', 'Bo220524', 'Re220317', 'Bo220327', 'Re220331', 'Re220411', 'Lo220513', 'Oc220412', 'Bo220328', 'Ve220316', 'Lo220520', 'Lo220519', 'Oc220512', 'Og220504', 'Ve220324', 'Oc220413', 'Og220520', 'Oc220430', 'Re220406', 'Og220519', 'Og220322', 'Lo220504', 'Bo220409', 'Re220319', 'Bo220331', 'Bo220413', 'Re220423', 'Bo220523', 'Bo220403', 'Bo220226', 'Lo220422', 'Lo220521', 'Ve220321', 'Re220418', 'Re220420', 'Bo220408', 'Bo220324', 'Bo220405', 'Ve220328', 'Og220506', 'Og220329', 'Lo220505', 'Re220402', 'Bo220418', 'Ve220305', 'Lo220501', 'Og220323', 'Bo220401', 'Ve220318', 'Re220330', 'Bo220319', 'Oc220422', 'Oc220503', 'Bo220521', 'Re220327', 'Re220424', 'Pa220502', 'Oc220418', 'Bo220407', 'Re220405', 'Re220419', 'Re220309', 'Oc220514', 'Og220319', 'Bo220323', 'Na220412', 'Og220510', 'Re220415', 'Og220516', 'Ve220311', 'Og220524', 'Lo220510', 'Lo220424', 'Oc220424', 'Re220316', 'Ve220308', 'Oc220506', 'Ve220314', 'Ve220323', 'Pa220429', 'Na220510', 'Oc220510', 'Re220417', 'Ve220310', 'Re220307', 'Bo220417', 'Ve220325', 'Ve220327', 'Bo220330', 'Re220310', 'Bo220526']\n",
      "222\n",
      "['Na', 'Re', 'Bo', 'Pa', 'Ve', 'Og', 'Lo', 'Oc']\n"
     ]
    }
   ],
   "source": [
    "#dat=pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/Bo220226/session_responses.p','rb'))\n",
    "print('Loading data...')\n",
    "dirs=os.listdir('/home/maria/Documents/HarvardData/processed_sessions_v3')\n",
    "dirs=[d for d in dirs if len(d.split('_'))==1]\n",
    "print(dirs)\n",
    "print(len(dirs))\n",
    "monkeys=list(set([f[:2] for f in dirs]))\n",
    "print(monkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lo220426', 'Re220308', 'Na220408', 'Na220509', 'Ve220408', 'Oc220410', 'Oc220505', 'Re220311', 'Bo220321', 'Lo220516', 'Bo220414', 'Og220407', 'Lo220511', 'Lo220430', 'Lo220421', 'Bo220420', 'Oc220511', 'Bo220402', 'Oc220417', 'Og220517', 'Lo220518', 'Lo220515', 'Re220326', 'Bo220322', 'Oc220406', 'Oc220502', 'Oc220416', 'Oc220428', 'Ve220407', 'Og220325', 'Lo220428', 'Re220413', 'Ve220302', 'Oc220513', 'Re220409', 'Og220507', 'Lo220502', 'Oc220509', 'Lo220517', 'Ve220312', 'Re220318', 'Pa220428', 'Re220421', 'Og220514', 'Lo220420', 'Re220306', 'Ve220317', 'Og220328', 'Lo220503', 'Re220404', 'Oc220423', 'Ve220313', 'Oc220421', 'Lo220508', 'Og220518', 'Re220425', 'Ve220228', 'Oc220420', 'Re220401', 'Ve220303', 'Og220523', 'Oc220409', 'Oc220504', 'Oc220415', 'Ve220322', 'Bo220406', 'Re220305', 'Ve220326', 'Ve220406', 'Pa220430', 'Bo220404', 'Bo220419', 'Lo220506', 'Pa220503', 'Ve220309', 'Ve220307', 'Re220422', 'Og220521', 'Re220414', 'Bo220325', 'Pa220504', 'Bo220329', 'Oc220419', 'Bo220412', 'Bo220320', 'Na220407', 'Og220513', 'Na220409', 'Ve220319', 'Ve220405', 'Ve220329', 'Bo220326', 'Oc220429', 'Na220406', 'Lo220507', 'Oc220414', 'Ve220409', 'Lo220509', 'Ve220413', 'Pa220505', 'Og220509', 'Og220321', 'Re220412', 'Na220411', 'Ve220404', 'Re220416', 'Bo220525', 'Bo220415', 'Og220503', 'Ve220301', 'Ve220315', 'Og220326', 'Re220320', 'Bo220312', 'Lo220514', 'Og220408', 'Og220512', 'Ve220304', 'Lo220427', 'Oc220411', 'Oc220507', 'Oc220426', 'Oc220425', 'Lo220423', 'Ve220412', 'Lo220429', 'Og220505', 'Oc220427', 'Og220324', 'Pa220506', 'Lo220425', 'Bo220416', 'Bo220524', 'Re220317', 'Bo220327', 'Re220331', 'Re220411', 'Lo220513', 'Oc220412', 'Bo220328', 'Ve220316', 'Lo220520', 'Lo220519', 'Oc220512', 'Og220504', 'Ve220324', 'Oc220413', 'Og220520', 'Oc220430', 'Re220406', 'Og220519', 'Og220322', 'Lo220504', 'Bo220409', 'Re220319', 'Bo220331', 'Bo220413', 'Re220423', 'Bo220523', 'Bo220403', 'Bo220226', 'Lo220422', 'Lo220521', 'Ve220321', 'Re220418', 'Re220420', 'Bo220408', 'Bo220324', 'Bo220405', 'Ve220328', 'Og220506', 'Og220329', 'Lo220505', 'Re220402', 'Bo220418', 'Ve220305', 'Lo220501', 'Og220323', 'Bo220401', 'Ve220318', 'Re220330', 'Bo220319', 'Oc220422', 'Oc220503', 'Bo220521', 'Re220327', 'Re220424', 'Pa220502', 'Oc220418', 'Bo220407', 'Re220405', 'Re220419', 'Re220309', 'Oc220514', 'Og220319', 'Bo220323', 'Na220412', 'Og220510', 'Re220415', 'Og220516', 'Ve220311', 'Og220524', 'Lo220510', 'Lo220424', 'Oc220424', 'Re220316', 'Ve220308', 'Oc220506', 'Ve220314', 'Ve220323', 'Pa220429', 'Na220510', 'Oc220510', 'Re220417', 'Ve220310', 'Re220307', 'Bo220417', 'Ve220325', 'Ve220327', 'Bo220330', 'Re220310', 'Bo220526']\n"
     ]
    }
   ],
   "source": [
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Na': [128, 128, 128, 128, 128, 128, 128, 128], 'Re': [76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76], 'Bo': [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64], 'Pa': [64, 64, 64, 64, 64, 64, 64, 64], 'Ve': [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128], 'Og': [65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 130, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65], 'Lo': [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128], 'Oc': [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]}\n",
      "781\n"
     ]
    }
   ],
   "source": [
    "shape_dct={m:[] for m in monkeys}\n",
    "for d in dirs:\n",
    "    #print('Loading data for monkey %s'%d)\n",
    "    dat=pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/%s/session_responses.p'%d,'rb'))\n",
    "    #print('Data loaded')\n",
    "    shape_dct[d[:2]].append(dat.shape[1])\n",
    "\n",
    "print(shape_dct)\n",
    "\n",
    "print(sum([shape_dct[m][0] for m in shape_dct]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93066, 128)\n",
      "(93066, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mega_array=[]\n",
    "clip_array=[]\n",
    "for d in dirs:\n",
    "    if d[:2]=='Ve':\n",
    "        dat=pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/%s/session_responses.p'%d,'rb'))\n",
    "        clip=pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/%s/clip_features.p'%d,'rb'))\n",
    "        #print(dat.shape)\n",
    "        mega_array.append(dat)\n",
    "        clip_array.append(clip)\n",
    "\n",
    "mega_array=np.vstack(mega_array)\n",
    "clip_array=np.vstack(clip_array)\n",
    "print(mega_array.shape)\n",
    "print(clip_array.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (65145, 512), (65145, 128)\n",
      "Validation shape: (9307, 512), (9307, 128)\n",
      "Test shape: (18614, 512), (18614, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.718e+05, tolerance: 7.144e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.118e+05, tolerance: 9.679e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+04, tolerance: 5.101e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.546e+05, tolerance: 1.408e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+04, tolerance: 8.167e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+05, tolerance: 2.917e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+05, tolerance: 1.005e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.494e+03, tolerance: 9.727e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+05, tolerance: 8.503e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.379e+05, tolerance: 1.124e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+05, tolerance: 7.409e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/maria/MousePipeline/.venv/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e+04, tolerance: 1.181e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Split the data into train, validation, and test sets\n",
    "# 70% train, 10% validation, 20% test\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# First split into train+validation and test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    clip_array, mega_array, test_size=test_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+validation into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=validation_ratio / (train_ratio + validation_ratio), random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Step 2: Perform grid search to find the best regularization parameter for Lasso\n",
    "alphas = np.logspace(-4, 1, 10)  # Regularization parameters to test\n",
    "best_alpha = None\n",
    "best_mse = float('inf')\n",
    "best_r2 = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha, random_state=42)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_val_pred = lasso.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "    r2 = r2_score(y_val, y_val_pred)  # Calculate R^2 (variance explained)\n",
    "    print(f\"Alpha: {alpha}, Validation MSE: {mse}, Variance Explained (R^2): {r2}\")\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_r2 = r2\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}, Best validation MSE: {best_mse}, Best validation R^2: {best_r2}\")\n",
    "\n",
    "# Step 3: Fit the Lasso model with the best alpha on the training data\n",
    "final_model = Lasso(alpha=best_alpha, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)  # Calculate R^2 on the test set\n",
    "\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test Variance Explained (R^2): {test_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (65145, 512), (65145, 128)\n",
      "Validation shape: (9307, 512), (9307, 128)\n",
      "Test shape: (18614, 512), (18614, 128)\n",
      "Alpha: 0.0001, Validation MSE: 256.69030680539515, Variance Explained (R^2): 0.011058139725604595\n",
      "Alpha: 0.003593813663804626, Validation MSE: 256.6868507402396, Variance Explained (R^2): 0.011066020520757742\n",
      "Alpha: 0.1291549665014884, Validation MSE: 256.68445351687956, Variance Explained (R^2): 0.011071759025795635\n",
      "Alpha: 4.641588833612782, Validation MSE: 256.65707826452683, Variance Explained (R^2): 0.011185143337956567\n",
      "Alpha: 166.81005372000593, Validation MSE: 256.24441355924415, Variance Explained (R^2): 0.012794376030563843\n",
      "Alpha: 5994.8425031894085, Validation MSE: 255.68000111188863, Variance Explained (R^2): 0.014805773606316373\n",
      "Alpha: 215443.46900318866, Validation MSE: 258.2668241884734, Variance Explained (R^2): 0.004484943988390747\n",
      "Alpha: 7742636.826811277, Validation MSE: 259.4086813427446, Variance Explained (R^2): 6.804456211723531e-05\n",
      "Alpha: 278255940.2207126, Validation MSE: 259.46346286288406, Variance Explained (R^2): -0.0001435850071468672\n",
      "Alpha: 10000000000.0, Validation MSE: 259.46502420170776, Variance Explained (R^2): -0.0001496170547727934\n",
      "Best alpha: 5994.8425031894085, Best validation MSE: 255.68000111188863, Best validation R^2: 0.014805773606316373\n",
      "Test MSE: 253.19444448813795\n",
      "Test Variance Explained (R^2): 0.01408972650015337\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Split the data into train, validation, and test sets\n",
    "# 70% train, 10% validation, 20% test\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# First split into train+validation and test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    clip_array, mega_array, test_size=test_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Then split train+validation into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=validation_ratio / (train_ratio + validation_ratio), random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Step 2: Perform grid search to find the best regularization parameter for Ridge\n",
    "alphas = np.logspace(-4, 10, 10)  # Regularization parameters to test\n",
    "best_alpha = None\n",
    "best_mse = float('inf')\n",
    "best_r2 = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha, random_state=42)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_val_pred = ridge.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, y_val_pred)\n",
    "    r2 = r2_score(y_val, y_val_pred)  # Calculate R^2 (variance explained)\n",
    "    print(f\"Alpha: {alpha}, Validation MSE: {mse}, Variance Explained (R^2): {r2}\")\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_r2 = r2\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}, Best validation MSE: {best_mse}, Best validation R^2: {best_r2}\")\n",
    "\n",
    "# Step 3: Fit the Ridge model with the best alpha on the training data\n",
    "final_model = Ridge(alpha=best_alpha, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)  # Calculate R^2 on the test set\n",
    "\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test Variance Explained (R^2): {test_r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
