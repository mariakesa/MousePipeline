{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 1250\n",
      "Training indices shape: (1000,)\n",
      "Number of test samples: 250\n",
      "Number of overlapping images between training and test sets: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Define paths\n",
    "image_path = '/home/maria/Documents/HarvardData/Images'\n",
    "session_ims = pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/Bo220226/session_images.p','rb'))\n",
    "\n",
    "# Construct full image paths\n",
    "image_paths = np.array([f\"{image_path}/{im.split('/')[2]}\" for im in session_ims])\n",
    "\n",
    "# Total number of images\n",
    "n_total = len(session_ims)\n",
    "print(f\"Total number of images: {n_total}\")\n",
    "\n",
    "# Define the number of training samples\n",
    "n_train = 1000\n",
    "\n",
    "# Ensure that n_train does not exceed n_total\n",
    "if n_train > n_total:\n",
    "    raise ValueError(\"Number of training samples exceeds the total number of available images.\")\n",
    "\n",
    "# Randomly select unique training indices without replacement\n",
    "training_path_inds = np.random.choice(n_total, size=n_train, replace=False)\n",
    "training_paths = image_paths[training_path_inds]\n",
    "\n",
    "# Determine test indices as those not in training_path_inds\n",
    "test_inds = np.setdiff1d(np.arange(n_total), training_path_inds)\n",
    "test_paths = image_paths[test_inds]\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Training indices shape: {training_path_inds.shape}\")  # Should be (1000,)\n",
    "print(f\"Number of test samples: {len(test_paths)}\")           # Should be n_total - 1000\n",
    "\n",
    "# Optional: Verify no overlap between training and test sets\n",
    "overlap = np.intersect1d(training_paths, test_paths)\n",
    "print(f\"Number of overlapping images between training and test sets: {len(overlap)}\")  # Should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images found: 1250\n",
      "Number of training samples: 1000\n",
      "Number of test samples: 250\n",
      "Number of overlapping images between training and test sets: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_743231/4282424885.py:115: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(augmented_X)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,256,256) into shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 119\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Apply augmentations to training images\u001b[39;00m\n\u001b[1;32m    118\u001b[0m num_augmentations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of augmentations per image\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m augmented_X \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of augmented images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maugmented_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Should be 1000 * 5 = 5000\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# 4. Preparing Neural Response Data\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Assuming y_train has shape [n_train, n_neurons]\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Replace this with your actual neural data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 115\u001b[0m, in \u001b[0;36mload_and_augment\u001b[0;34m(image_paths, num_augmentations)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;66;03m# Optionally, handle corrupted images or skip\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_X\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,256,256) into shape (3,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "# ================================\n",
    "# 1. Setup and Image Path Handling\n",
    "# ================================\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# Define base image directory and possible extensions\n",
    "base_image_dir = '/home/maria/Documents/HarvardData/Images'\n",
    "possible_extensions = ['.jpg', '.JPG', '.png', '.PNG']\n",
    "\n",
    "# Load session image identifiers\n",
    "session_ims = pickle.load(open('/home/maria/Documents/HarvardData/processed_sessions_v3/Bo220226/session_images.p','rb'))\n",
    "\n",
    "# Function to find the correct image path with existing extension\n",
    "def find_image_path(session_ims, base_image_dir, possible_extensions):\n",
    "    image_paths = []\n",
    "    for p in session_ims:\n",
    "        # Extract the filename after 'OOD_monkey_data/Images/'\n",
    "        if 'OOD_monkey_data/Images/' in p:\n",
    "            filename = p.split('OOD_monkey_data/Images/')[-1]\n",
    "        else:\n",
    "            filename = os.path.basename(p)  # Fallback to basename\n",
    "        \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        \n",
    "        # Try each possible extension until a file is found\n",
    "        found_path = None\n",
    "        for ext_candidate in possible_extensions:\n",
    "            candidate_path = os.path.join(base_image_dir, base_name + ext_candidate)\n",
    "            if os.path.exists(candidate_path):\n",
    "                found_path = candidate_path\n",
    "                break\n",
    "        \n",
    "        if found_path is None:\n",
    "            # If no matching file is found, warn and skip\n",
    "            print(f\"Warning: No matching file found for base name: {base_name}\")\n",
    "            # Optionally, append a placeholder or handle as needed\n",
    "            # image_paths.append('/path/to/placeholder.jpg') # Uncomment if using placeholders\n",
    "        else:\n",
    "            image_paths.append(found_path)\n",
    "    \n",
    "    return np.array(image_paths)\n",
    "\n",
    "# Get the array of valid image paths\n",
    "image_paths = find_image_path(session_ims, base_image_dir, possible_extensions)\n",
    "print(f\"Total valid images found: {len(image_paths)}\")\n",
    "\n",
    "# ================================\n",
    "# 2. Splitting the Dataset\n",
    "# ================================\n",
    "\n",
    "# Define the number of training samples\n",
    "n_train = 1000\n",
    "\n",
    "# Ensure that n_train does not exceed the total number of images\n",
    "if n_train > len(image_paths):\n",
    "    raise ValueError(\"Number of training samples exceeds the total number of available images.\")\n",
    "\n",
    "# Generate unique training indices without replacement\n",
    "training_path_inds = np.random.choice(len(image_paths), size=n_train, replace=False)\n",
    "training_paths = image_paths[training_path_inds]\n",
    "\n",
    "# Determine test indices as the complement of training indices\n",
    "test_inds = np.setdiff1d(np.arange(len(image_paths)), training_path_inds)\n",
    "test_paths = image_paths[test_inds]\n",
    "\n",
    "print(f\"Number of training samples: {len(training_paths)}\")  # Should be 1000\n",
    "print(f\"Number of test samples: {len(test_paths)}\")          # Should be len(image_paths) - 1000\n",
    "\n",
    "# Optional: Verify no overlap\n",
    "overlap = np.intersect1d(training_paths, test_paths)\n",
    "print(f\"Number of overlapping images between training and test sets: {len(overlap)}\")  # Should be 0\n",
    "\n",
    "# ================================\n",
    "# 3. Data Augmentation\n",
    "# ================================\n",
    "\n",
    "# Define your data augmentation pipeline\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # Adjust based on image channels\n",
    "])\n",
    "\n",
    "# Function to load and augment images\n",
    "def load_and_augment(image_paths, num_augmentations=5):\n",
    "    augmented_X = []\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            image = Image.open(path).convert('RGB')  # Ensure 3 channels\n",
    "            image_np = np.array(image)\n",
    "            for _ in range(num_augmentations):\n",
    "                augmented_image = augmentation_transform(image_np)\n",
    "                augmented_X.append(augmented_image.numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path}: {e}\")\n",
    "            # Optionally, handle corrupted images or skip\n",
    "    return np.array(augmented_X)\n",
    "\n",
    "# Apply augmentations to training images\n",
    "num_augmentations = 5  # Number of augmentations per image\n",
    "augmented_X = load_and_augment(training_paths, num_augmentations=num_augmentations)\n",
    "print(f\"Number of augmented images: {augmented_X.shape[0]}\")  # Should be 1000 * 5 = 5000\n",
    "\n",
    "# ================================\n",
    "# 4. Preparing Neural Response Data\n",
    "# ================================\n",
    "\n",
    "# Load neural response data\n",
    "# Replace the following lines with your actual data loading mechanism\n",
    "# For example, if neural data is stored in a pickle file:\n",
    "# neural_data = pickle.load(open('/path/to/neural_data.p','rb'))\n",
    "\n",
    "# Placeholder neural data\n",
    "# Assuming y_train has shape [n_train, n_neurons]\n",
    "# Replace this with your actual neural data\n",
    "n_neurons = 64  # Example number of neurons\n",
    "y_train = np.random.rand(n_train, n_neurons)  # Replace with actual data\n",
    "\n",
    "# Similarly, load neural responses for test set\n",
    "# y_test = ...  # Shape: [n_test, n_neurons]\n",
    "y_test = np.random.rand(len(test_paths), n_neurons)  # Replace with actual data\n",
    "\n",
    "# For augmented data, assuming neural responses are invariant\n",
    "augmented_y = np.repeat(y_train, repeats=num_augmentations, axis=0)  # Shape: [n_train * num_augmentations, n_neurons]\n",
    "print(f\"Shape of augmented_y: {augmented_y.shape}\")  # Should be [5000, 64]\n",
    "\n",
    "# ================================\n",
    "# 5. Combining Original and Augmented Data\n",
    "# ================================\n",
    "\n",
    "# Convert original training images to tensors and normalize similarly\n",
    "def preprocess_image_original(path):\n",
    "    try:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        image_tensor = augmentation_transform(image_np)\n",
    "        return image_tensor.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        return np.zeros((3, 224, 224))  # Example placeholder, adjust as needed\n",
    "\n",
    "# Load and preprocess original training images\n",
    "original_X = []\n",
    "for path in training_paths:\n",
    "    original_X.append(preprocess_image_original(path))\n",
    "original_X = np.array(original_X)\n",
    "print(f\"Number of original training images after preprocessing: {original_X.shape[0]}\")  # Should be 1000\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_combined = np.vstack((original_X, augmented_X))  # Shape: [6000, C, H, W]\n",
    "y_combined = np.vstack((y_train, augmented_y))    # Shape: [6000, n_neurons]\n",
    "\n",
    "print(f\"Combined training data shape: {X_combined.shape}, Combined labels shape: {y_combined.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 6. Creating PyTorch Datasets and DataLoaders\n",
    "# ================================\n",
    "\n",
    "# Convert combined data to PyTorch tensors\n",
    "X_combined_tensor = torch.tensor(X_combined, dtype=torch.float32)\n",
    "y_combined_tensor = torch.tensor(y_combined, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_combined_tensor, y_combined_tensor)\n",
    "\n",
    "# Assign higher weights to original data to prioritize labeled samples\n",
    "weights = torch.ones(len(dataset))\n",
    "weights[:n_train] = 2.0  # Higher weight for original data\n",
    "\n",
    "# Create a WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "# Define DataLoader\n",
    "batch_size = 64\n",
    "loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "# ================================\n",
    "# 7. Defining the Mixture of Experts (MoE) Model\n",
    "# ================================\n",
    "\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_size, num_experts, hidden_size, output_size, dropout_rate=0.3):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # Define experts\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_size, output_size)\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        # Define gating network\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_size, num_experts),\n",
    "            nn.Softmax(dim=1)  # Outputs weights for each expert\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten images if necessary (assuming x has shape [batch_size, C, H, W])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Get gating weights\n",
    "        gating_weights = self.gate(x)  # Shape: [batch_size, num_experts]\n",
    "        # Get expert outputs\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)  # Shape: [batch_size, num_experts, output_size]\n",
    "        # Weighted sum of expert outputs\n",
    "        out = torch.sum(gating_weights.unsqueeze(2) * expert_outputs, dim=1)  # Shape: [batch_size, output_size]\n",
    "        return out\n",
    "\n",
    "# ================================\n",
    "# 8. Training the Mixture of Experts (Student) Model\n",
    "# ================================\n",
    "\n",
    "# Define model parameters\n",
    "input_size = X_combined_tensor.shape[1] * X_combined_tensor.shape[2] * X_combined_tensor.shape[3]  # C * H * W\n",
    "num_experts = 3\n",
    "hidden_size = 128\n",
    "output_size = y_combined_tensor.shape[1]  # Number of neurons\n",
    "dropout_rate = 0.3\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize the Mixture of Experts model\n",
    "model = MixtureOfExperts(input_size, num_experts, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Early Stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "# Prepare validation data (e.g., 10% of the training set)\n",
    "val_size = int(0.1 * n_train)\n",
    "X_val_paths = training_paths[-val_size:]\n",
    "y_val = y_train[-val_size:]\n",
    "# Preprocess validation images\n",
    "def preprocess_image_val(path):\n",
    "    try:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        image_tensor = augmentation_transform(image_np)\n",
    "        return image_tensor.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        return np.zeros((3, 224, 224))  # Example placeholder, adjust as needed\n",
    "\n",
    "# Load and preprocess validation images\n",
    "X_val = []\n",
    "for path in X_val_paths:\n",
    "    X_val.append(preprocess_image_val(path))\n",
    "X_val = np.array(X_val)\n",
    "y_val = y_train[-val_size:]\n",
    "\n",
    "# Convert validation data to tensors\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create validation DataLoader\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "y_val_tensor = y_val_tensor.to(device)\n",
    "\n",
    "# Adjust DataLoader to move batches to the appropriate device\n",
    "def get_device_loader(loader, device):\n",
    "    for batch in loader:\n",
    "        yield [item.to(device) for item in batch]\n",
    "\n",
    "# Training loop with Early Stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.to(device)\n",
    "            \n",
    "            val_outputs = model(X_val_batch)\n",
    "            loss = criterion(val_outputs, y_val_batch)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_moe_student_model.pth')  # Save the best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        avg_epoch_loss = epoch_loss / len(loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_moe_student_model.pth'))\n",
    "model.to('cpu')  # Move back to CPU for evaluation if needed\n",
    "\n",
    "# ================================\n",
    "# 9. Evaluating the Student Model on the Test Set\n",
    "# ================================\n",
    "\n",
    "# Preprocess test images\n",
    "def preprocess_image_test(path):\n",
    "    try:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        image_tensor = augmentation_transform(image_np)\n",
    "        return image_tensor.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        return np.zeros((3, 224, 224))  # Example placeholder, adjust as needed\n",
    "\n",
    "# Load and preprocess test images\n",
    "X_test = []\n",
    "for path in test_paths:\n",
    "    X_test.append(preprocess_image_test(path))\n",
    "X_test = np.array(X_test)\n",
    "print(f\"Number of test images after preprocessing: {X_test.shape[0]}\")\n",
    "\n",
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Move test data to device\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).cpu().numpy()\n",
    "    y_test_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Calculate R² scores for each neuron\n",
    "variance_explained_test = r2_score(y_test_true, y_test_pred, multioutput=\"raw_values\")\n",
    "mean_r2_test = np.mean(variance_explained_test)\n",
    "\n",
    "print(f\"Mean R² on Test Set: {mean_r2_test:.4f}\")\n",
    "\n",
    "# Optionally, analyze individual neuron performance\n",
    "for idx, r2 in enumerate(variance_explained_test):\n",
    "    print(f\"Neuron {idx+1}: R² = {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
